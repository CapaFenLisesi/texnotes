\chapter{Derivatives}
\epigraph{Some people will tell you that slow is good---but I'm here to tell you that fast is better.}{Hunter S. Thompson}%, Kingdom of Fear: Loathsome Secrets of a Star-crossed Child in the Final Days of the American Century}

Say we are trying to find the rate of change of the function $x^3$.
That is, essentially, its slope.
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/x3.eps}
  \end{center}
  \caption{A plot of $x^3$.}
\end{figure}
We'd like to be able to do this with just a straight line, but that's simply not possible.
We could, however, draw a straight line that approximates this function around a specific value, say $x=1$.
We can just draw a line that approximates the function, to try to get it right:
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/x3_1.eps}
  \end{center}
\end{figure}
But that's not a very accurate impression of our slope.
To make it better, we could draw a line between two points that are \emph{even closer} to $x=1$.
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/x3_2.eps}
  \end{center}
\end{figure}
And to improve this further, we can continue to draw lines closer and closer to that point.
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/x3_3.eps}
  \end{center}
\end{figure}
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/x3_4.eps}
  \end{center}
\end{figure}
Until we are drawing lines between two points which are an \emph{infinitely small} distance apart from one another.
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/x3vline.eps}
  \end{center}
  %\caption{A plot of $x^3$ and $3x-2$.}
\end{figure}
The slope of this line is the \emph{derivative} of our function at $x=1$.

We see that, around $x=1$, our slopes are very close.
But as we get further from that $x$-value, we don't have a very good approximation of the slope anymore.
This is because a derivative describes the \emph{instantaneous rate of change} of the function \emph{at that point}.
It's not the slope of the entire function, it's just the slope at one, specific, selected point.

The \textbf{derivate}\index{derivative} of a function $f(x)$ at $x=a$ is used to describe its \emph{instantaneous slope} the value $x=a$.

\section{Slopes}
\index{slope}
The entire idea of a derivative is based on the idea behind the slope of a graph.
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/lineform.eps}
  \end{center}
  \caption{The general form equation for a line.}
\end{figure}
The slope, $m$, of a given straight line\footnote{$b$ is the \emph{y-intercept} of the function.}
$f(x)=mx+b$ is given by its \emph{change in $y$ values divided by its change in $x$ values}
\begin{align}
  \label{eq:slope}
  m&=\frac{\Delta y}{\Delta x,} \\
  \intertext{which we can find using the formula}
  m&=\frac{y_2-y_1}{x_2-x_1,} \\
  \intertext{which is equivalent to}
  m&=\frac{f(x_2)-f(x_1)}{x_2-x_1.}
\end{align}
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/lineform_slope.eps}
  \end{center}
  \caption{How we determine slope in a graph.}
\end{figure}
% In early mathematics courses, slope is often described as the ``rise'' over ``run'' of a graph.
% While this is accurate, it doesn't provide the complete picture.
% What a \emph{slope} really describes is how much a given function $f(x)$ is altering each of its input values $x$, often heard as ``change in $y$ over change in $x$.''
% You'll notice that this is independent of any initial value $b$ selected for a linear function.\footnote{Which is why all constants disappear when you take the derivative of a function.}

\section{The Difference Quotient}\index{difference quotient}

The \emph{difference quotient} works the same way as the slope formula, except we treat how far apart our two $x$ values are as a variable.
\begin{equation}
  \frac{\Delta f(x)}{\Delta x}=\frac{f(x+\Delta x)-f(x)}{\Delta x}
\end{equation}
So $\Delta x=x_2-x_1$, and $x=x_1$.
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/diffquot.eps}
  \end{center}
  \caption{A visual representation of the difference quotient on a line.}
\end{figure}
You'll often see the difference quotient written with $\Delta x \to h$ as
\begin{equation}
  \frac{\Delta f(x)}{\Delta x}=\frac{f(x+h)-f(x)}{h}
\end{equation}

\subsection{Limit Definition of Derivatives}

The difference quotient is used in the \textbf{limit definition of a derivative}\index{derivative, limit definition}, which is
\begin{equation}
  \label{eq:limitdef}
  \frac{\ud f(x)}{\ud x}=\lim_{h \to 0} \frac{f(x+h)-f(x)}{h}
\end{equation}
% Notice that the only distinction between this equation and the difference quotient/slope equation from earlier is the introduction of a limit. The idea behind that limit is that you're calculating the slope of a function as the distance between your $x_2$ and $x_1$ values becomes infinitely small ($h\to 0$). We call this distance an \emph{infinitesimal}: a distance smaller than any feasible measurement, but not zero in size.
%
% So what a derivative of a function is going to tell us is how the function behaves (its slope) at a particular ``infinitely small'' portion of the graph, which might as well be a point.
%
% For linear functions, the function behaves the same no matter where you look at it, so their derivatives are always constant and equal to the slope of the function.
%
% For nonlinear functions, like $f(x)=x^2$, the derivative will yield a function (in this case, just $f'(x)=2x$), because the function is changing its input values differently depending on where you are looking. Near the origin, where $x=0$, the derivative is zero and any $x$ value will give $y$ values not too far from the original input. But as you move further from the origin, the ratio of $y/x$ gets larger and larger, and the derivative in turn gets bigger and bigger.
% \begin{figure}[H]
%     \begin{center}
%       \includegraphics[width=0.5\textwidth]{continuous/derivatives/xsquared.eps}
%       \caption{A graph of $f(x)=x^2$ and $f'(x)=2x$.}
%     \end{center}
% \end{figure}

\section{Notation Used with Derivatives}

There are a number of ways to denote the derivative of a function $y=f(x)$. The most common notation early on in calculus classes is the \emph{prime} notation $y'$ and $f'$ because it is the simplest. Later on, you often see $\ud/\ud x$ style notation, because it is more specific. It tells us not only which function we are differentiating, but with respect to which variable. A notable characteristic of this ``d notation'' is the similarity it provides to our equation for slope:
\begin{align*}
  &m=\frac{\Delta y}{\Delta x}=\frac{\Delta f(x)}{\Delta x} &y'=\frac{\ud y}{\ud x}=\frac{\ud f(x)}{\ud x}
\end{align*}
In the case of slope, we're talking about specific $y$ and $x$ values, but in the case of a derivative, we're talking about \emph{infinitesimals}, and that particular distinction allows us to discuss the behavior of functions that aren't linear, but change their behavior over time.

\section{Tangent Lines}

Remember our line that gave us the slope of $f(x)=x^3$ at $x=1$?
\begin{figure}[H]
  \begin{center}
    \includegraphics[width=0.5\textwidth]{continuous/derivatives/x3vline.eps}
  \end{center}
  %\caption{A plot of $x^3$ and $3x-2$.}
\end{figure}
That was called a \emph{tangent line} to $f(x)$ at that point.
How do we find out what the equation for that line is?

Well, we use the derivative of the function, calculated at $x=1$, to determine the slope of our tangent line.
\begin{align*}
  f(x)&=x^3\\
  f'(x)&=\lim_{h \to 0} \frac{f(x+h)-f(x)}{h} \\
  \intertext{Remembering back to Section \ref{sec:compositefunctions},}
  f'(x)&=\lim_{h \to 0} \frac{(x+h)^3-x^3}{h} \\
  \intertext{Expand $(x+h)^3$.}
  f'(x)&=\lim_{h \to 0} \frac{(x+h)(x+h)(x+h)-x^3}{h} \\
  f'(x)&=\lim_{h \to 0} \frac{(x^2+hx+hx+h^2)(x+h)}{h} \\
  f'(x)&=\lim_{h \to 0} \frac{(x^2+2hx+h^2)(x+h)}{h} \\
  f'(x)&=\lim_{h \to 0} \frac{x^3+2hx^2+h^2x+x^2h+2h^2x+h^3-x^3}{h} \\
  f'(x)&=\lim_{h \to 0} \frac{3hx^2+3h^2x+h^3}{h} \\
  f'(x)&=\lim_{h \to 0} 3x^2+3hx+h^2 \\
  \intertext{Since we are taking the limit as $h\to0$,}
  f'(x)&=3x^2
\end{align*}
If we calculate this derivative at $x=1$, we get
\begin{align*}
  f'(x)\Big|_{x=1}&=3(1)^2 \\
  &=3
\end{align*}
So the slope of our tangent line is $3$.
But that was an awful lot of work just to get one little derivative!
It would be handy if we could generalize the derivative of functions like this, so that we don't have to do it again in the future.
Luckily, we can, and this generalization is what we call the \emph{power rule}.

The \textbf{power rule}\index{power rule} states that
\begin{equation}
  \ddx x^n=nx^{n-1}
\end{equation}

% The \emph{tangent line} to a graph at a point is just a line that acts like the function is linear and behaves exactly as the graph does at that point. This is useful for visualizing the derivative, and showing us how the behavior of a function can change depending on its $(x,y)$ location.

% \begin{figure}[H]
%   \begin{center}
%     \includegraphics[width=0.4\textwidth]{continuous/derivatives/tangent.eps}
%   \end{center}
%   \caption{A tangent line to the graph of $f(x)=x^2$.}
% \end{figure}
%
% To calculate the equation for a tangent line at a point, simply find the
% derivative of the function at that point and treat that as the slope of the
% tangent line. Then, use the $(x, y)$ values of the point to produce the tangent line's function
% using the point-slope equation (\eqref{eq:pointslope}).
\subsection{Derivative Rules}

Derivative rules are just shorthands for working things out manually using the
limit definition in equation \eqref{eq:limitdef}. They all come from equation \eqref{eq:limitdef}, but they serve as generalizations to greatly simplify the work we have to do in calculating derivatives.

\subsubsection{Constant Rule}

The derivate of a constant is always zero. A constant has no rate of change.
\[\ddx k=0\]

\subsubsection{Product Rule}

The product rule states that
\begin{equation}
  \ddx (uv)=u \frac{\ud v}{\ud x}+v\frac{\ud u}{\ud x}
\end{equation}

\subsubsection{Quotient Rule}

The quotient rule states that
\begin{equation}
  \frac{\ud}{\ud x}\left(\frac{u}{v}\right)=\frac{v\frac{\ud u}{\ud x}-u\frac{\ud v}{\ud x}}{v^2}
\end{equation}

\subsubsection{Chain Rule}

The chain rule states that if $y=f(u)$ and $u=g(x)$, then
\begin{equation}
  \frac{\ud y}{\ud x}=\frac{\ud y}{\ud u} \cdot \frac{\ud u}{\ud x}
\end{equation}

The chain rule is used to differentiate composite functions, which look like $(f \circ g)(x)$ and mean $f(g(x))$. You'll want to develop an intuitive understanding for when to use the chain rule.
\begin{ex}
  Find the derivative of $f(x)$, where
  \[ f(x)=\frac{1}{x^3} \]
  \begin{figure}[h]
    \begin{center}
      \includegraphics{continuous/derivatives/chainrule_1.eps}
    \end{center}
    \caption{A plot of $f(x)=\frac{1}{x^3}$.}
  \end{figure}
  \begin{sol}
    This is not a chain rule problem. Although you could think of it as one with $f(x)=1/x$ and $g(x)=x^3$, it is easier to remember that factors can be moved from the numerator to the denominator simply by multiplying their exponents by $-1$.
    \begin{align*}
      f(x)&=\frac{1}{x^3}\\&=x^{-3} \\
      \ddx f(x)&=-3x^{-4}
    \end{align*}
  \end{sol}
\end{ex}
\begin{ex}
  Find the derivative of $f(x)$, where
  $$ f(x)=\left(\frac{1}{\sqrt{x}}\right)^5 $$
  This is a chain rule problem. We use
  \begin{align*}
    & g(x)=\frac{1}{\sqrt{x}}
    & & f(x)={(g(x))^5}
  \end{align*}
  \begin{align*}
    \ddx f(x)&=\ddx \left(\frac{1}{\sqrt{x}}\right)^5 \\
      &= \ddx {(g(x))^5} \\
      &= 5g(x)^4 \cdot \ddx g(x)
  \end{align*}
  Now we find $ \ddx g(x) $
  \begin{align*}
    \ddx g(x) &= \ddx \frac{1}{\sqrt{x}} =\ddx \frac{1}{x^{1/2}} =\ddx x^{-1/2} \\
      &=\frac{-1}{2}x^{-3/2} =\frac{-1}{2x^{3/2}} \\
      &=\frac{-1}{2\sqrt{x^3}}
  \end{align*}
  and plug that back into our original derivative, along with $g(x)=\frac{1}{\sqrt{x}}$
  \begin{align*}
    \ddx f(x)&=5g(x)^4 \cdot \ddx g(x) \\
      &=5\left(\frac{1}{\sqrt{x}}\right)^4\cdot \frac{-1}{2\sqrt{x^3}}
  \end{align*}
  and simplify
  \begin{align*}
    \ddx f(x)&=5\left(\frac{1}{\sqrt{x}}\right)^4\cdot \frac{-1}{2\sqrt{x^3}} =5\left[\frac{1^4}{\left(\sqrt{x}\right)^4}\right] \cdot \frac{-1}{2\sqrt{x^3}} \\
    &=5\left[\frac{1}{\left(x^{1/2}\right)^4}\right] \cdot \frac{-1}{2\sqrt{x^3}}=5\left[\frac{1}{x^{4/2}}\right] \cdot \frac{-1}{2\sqrt{x^3}} \\
    &=5\left[\frac{1}{x^2}\right] \cdot \frac{-1}{2\sqrt{x^3}}=\frac{5}{x^2} \cdot \frac{-1}{2\sqrt{x^3}} \\
    &=\frac{-5}{2x^2\sqrt{x^3}} =\frac{-5}{2x^2\cdot x^{3/2}} \\
    &=\frac{-5}{2x^{4/2}\cdot x^{3/2}}\\
    &=\frac{-5}{2x^{7/2}} \\
  \end{align*}
\end{ex}
\subsubsection{Trigonometric Derivative Rules}
\begin{align}
  \ddx \sin x &= \cos x & \ddx \sec x &= \sec x \tan x \\
  \ddx \cos x &= -\sin x & \ddx \csc x &= -\cot x \csc x \\
  \ddx \tan x &= \sec^2 x & \ddx \cot x &= -\csc^2 x
  \label{trigderiv}
\end{align}
Many of these trig derivatives, such as the derivative of $\tan x$, can be found from simpler derivative rules.
\begin{ex}
  \[\ddx \tan x\]
  \begin{sol}
    \begin{align*}
      \ddx \tan x &= \ddx \frac{\sin x}{\cos x} \\
      &= \frac{\ddx (\sin x) \cos x - \ddx (\cos x) \sin x}{(\cos x)^2}\\
      &=\frac{\cos^2 x+\sin^2 x}{\cos^2 x}\\
      &=\frac{1}{\cos^2 x}\\
      &=\sec^2 x
    \end{align*}
  \end{sol}
\end{ex}
\subsection{Differentiability}
  A function $f(x)$ is differentiable at a point $x_0$ if a tangent line to its curve exists at that point and is not vertical. Functions are not differentiable at breaks, immediate bends, cusps, or places with vertical tangents.

\subsection{Graphing Functions}
To graph a function:
  \begin{enumerate}
   \item Find all \textbf{critical values}. Critical values are locations where $\frac{\ud y}{\ud x}=0$ or is undefined.\footnote{At locations where $\frac{\ud y}{\ud x}=0$, the tangent line is horizontal.}
   \item Find all \textbf{points of inflection}. These are locations where the second derivative ($\frac{\ud^2y}{\ud x}$) is zero or undefined.
   \item Determine where $\frac{\ud y}{\ud x}$ is \emph{positive} to find where $f(x)$ is \emph{increasing}. Remember that a derivative signifies the slope of a graph, so a positive derivative implies that the graph is increasing. This can be achieved either by testing values on each side of a \emph{critical value}, or by intuitive understanding. For example, $\frac{\ud y}{\ud x}=3x^2$ is positive everywhere except at $x=0$, so $f(x)=y$ is increasing everywhere except for at its horizontal tangent at $x=0$.\footnote{$x^2$ can never produce a negative number, because a negative times a negative or a positive times a positive is always positive}
   \item Determine where $\frac{\ud y}{\ud x}$ is \emph{negative} to find where $f(x)$ is \emph{decreasing}.
   \item Determine the sign of $\frac{\ud^2y}{\ud x}$ on both sides of all \emph{points of inflection}. The graph is \emph{concave up} where $\frac{\ud^2y}{\ud x}$ is positive, and \emph{concave down} where $\frac{\ud^2y}{\ud x}$ is negative.
  \end{enumerate}
  % from my notes in Dr. Dobrescu's Math 140 class, Fall 2011
\section{l'Hospital's Rule}\label{lhospital}\index{l'Hospital's Rule}

\textbf{l'Hospital's Rule} uses derivatives to calculate limits\index{limits} of fractions whose numerators and denominators both approach the same indeterminate for, which can be either zero or $\infty$. Limits involving transcendental functions\index{transcendental functions} often require some use of the rule for their calculation.

\begin{theorem}[L'Hospital's Rule]\label{th:lhospital}
  Suppose that $f(a)=g(a)=0$, that $f$ and $g$ are differentiable on an open interval $I$ containing $a$, and that $g'(x) \neq 0$ on $I$ if $x \neq a$. Then
  \[ \lim_{x \to a} \frac {f(x)}{g(x)} \=H \lim_{x \to a} \frac{f'(x)}{g'(x)} \]
  assuming that the limit on the right side of this equation exists.
\end{theorem}
\begin{remark}
  L'Hopital's Rule does not apply when either the numerator or the denominator has a finite nonzero limit.
\end{remark}
\begin{proof}
  We first establish the limit equation for the case $x \to a^+$. The method needs almost no change to apply to $x \to a^{-}$, and the combination of these two cases establishes the result.

  Suppose that $x$ lies to the right of $a$. Then $g'(x) \neq 0$, and we can apply Cauchy's Mean Value Theorem to the closed interval from $a$ to $x$. This step produces a number $c$ between $a$ and $x$ such that
  $$ \frac{f'(c)}{g'(c)}=\frac{f(x)-f(a)}{g(x)-g(a)} $$
  But $f(a)=g(a)$, so
  $$ \frac{f'(c)}{g'(c)}=\frac{f(x)}{g(x)} $$
  As $x$ approaches $a$, $c$ approaches $a$ because it always lies between $a$ and $x$. Therefore,
  $$ \lim_{x \to a^+} \frac{f(x)}{g(x)}=lim_{c \to a} \frac{f'(c)}{g'(c)} = lim_{x \to a^+} \frac{f'(x)}{g'(x)} $$
  which establishes l'Hospital's Rule for the case where $x$ approaches $a$ from
  above. The case where $x$ approaches $a$ from below is proved by applying
  Cauchy's Mean Value Theorem to the closed interval $[x,a], x <
  a$.\cite{thomas}
\end{proof}
\begin{figure}[h]
  \begin{center}
    \includegraphics[width=0.2\textwidth]{photos/cauchy.jpg}
  \end{center}
  \caption{Augustin Louis Cauchy, 1901.}
\end{figure}
\begin{theorem}[Cauchy's Mean Value Theorem]\label{th:caunchymv}\index{Cauchy's Mean Value Theorem}
Suppose functions $f$ and $g$ are continuous on $[a, b]$ and differentiable throughout $(a, b)$ and also suppose $g'(x) \neq 0$ throughout $(a, b)$. Then there exists a number $c$ in $(a, b)$ at which
  \[ \frac {f'(c)}{g'(c)} = \frac{f(b)-f(a)}{g(b)-g(a)} \]
\end{theorem}
\section{Derivatives of Inverses of Differentiable Functions}\index{inverse
functions}

\begin{theorem}[The Derivative Rule for Inverses]\label{th:invderiv}
  If $f$ has an interval $I$ as domain and $f'(x)$ exists and is never zero on $I$, then $f^{-1}$ is differentiable at every point in its domain (the range of $f$). The value of $\big(f^{-1}\big)'$ at a point $b$ in the domain of $f^{-1}$ is the reciprocal of the value of $f'$ at the point $a=f^{-1}(b)$:
  \begin{equation}
    \big(f^{-1}\big)'(b)=\frac{1}{f'\big(f^{-1}(b)\big)}
  \end{equation}
  This can also be written
  \begin{equation}
    \cfrac{\ud f^{-1}}{\ud x}\bigg|_{x=b}=\cfrac{1}{\cfrac{\ud f}{\ud x}\bigg|_{x=f^{-1}(b)}}
  \end{equation}
  \begin{proof}
  Because a function applied to the inverse of itself should return its own input value, we can start with this relationship.
    \begin{align*}
      f \big( f^{-1}(x) \big) &= x \\
      \intertext{From here, take the derivative of both sides. On the left, we do so in notation only. On the right, we know that the derivative of a variable representing a constant is always 1.}
      \frac{\ud}{\ud x} f\big(f^{-1}(x)\big) &= 1\\
      \intertext{Because the lefthand side includes the composition of functions, we must use the chain rule in calculating its derivative. Applying the chain rule to the lefthand side of the equation gives us}
      f'\big(f^{-1}(x)\big)\cdot \cfrac{\ud}{\ud x}f^{-1}(x) &= 1  \\
      \intertext{Now, we divide each side of the equation by $f' \big( f^{-1}(x) \big)$ to solve for the derivative only.}
      \frac{\ud}{\ud x}f^{-1}(x) &= \cfrac{1}{f'\big(f^{-1}(x)\big)}\qedhere
    \end{align*}
  \end{proof}
\end{theorem}
